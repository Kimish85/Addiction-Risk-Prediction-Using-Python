{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Install and Import"
      ],
      "metadata": {
        "id": "U_KVs4efSutx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKzXiBu2SI-5"
      },
      "outputs": [],
      "source": [
        "!pip install shap"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Load Model and Training Data"
      ],
      "metadata": {
        "id": "4O_m4OhKSwMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# --- Load Your Model ---\n",
        "model = joblib.load('random_forest_model.pkl')\n",
        "\n",
        "# --- Load Your Data ---\n",
        "# We need the training data (X) to create the explainer\n",
        "# Load the *balanced* dataset you used for training\n",
        "df = pd.read_csv('balanced_dataset.csv')\n",
        "\n",
        "# --- Recreate your Train/Test Split ---\n",
        "# This is to get an 'X_train' that SHAP can use as a reference\n",
        "# Make sure to use the same features your model was trained on\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "# Adjust these columns based on your final model\n",
        "X = df.drop(columns=['Substances_Used', 'substances_used_label'])\n",
        "y = df['Substances_Used']\n",
        "\n",
        "# Use the same random_state!\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Model, SHAP, and Data are ready.\")"
      ],
      "metadata": {
        "id": "Kf90hC-6SrP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Create the SHAP Explainer"
      ],
      "metadata": {
        "id": "I1mnKWLcS1oW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Initialize JavaScript visualization in the notebook\n",
        "shap.initjs()\n",
        "\n",
        "# 2. Create the explainer object\n",
        "# We pass the model and the training data\n",
        "explainer = shap.TreeExplainer(model, X_train)\n",
        "\n",
        "# 3. Calculate SHAP values for your *test* data\n",
        "# This can take a moment\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "print(\"SHAP values calculated.\")"
      ],
      "metadata": {
        "id": "yZgIdxJqSrK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Global Interpretability (Which features matter most overall?)"
      ],
      "metadata": {
        "id": "-wFiCqfxS189"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming class '1' (Yes) is the one we care about\n",
        "# Check shap_values.shape to confirm. If you have two classes (0, 1),\n",
        "# shap_values will be a list of two arrays. We'll use index 1.\n",
        "\n",
        "st.set_option('deprecation.showPyplotGlobalUse', False)\n",
        "\n",
        "# Create a summary plot (beeswarm plot)\n",
        "st.write(\"### Global Feature Importance\")\n",
        "st.write(\"Which features have the most impact on the prediction?\")\n",
        "shap.summary_plot(shap_values[1], X_test, plot_type=\"bar\", show=False)\n",
        "st.pyplot(bbox_inches='tight')"
      ],
      "metadata": {
        "id": "_J8k7TINSrG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Local Interpretability (Why did this one person get this score?)"
      ],
      "metadata": {
        "id": "yU6vPVXcTCos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's explain the prediction for the *first person* in the test set\n",
        "row_index = 0\n",
        "X_sample = X_test.iloc[[row_index]]\n",
        "\n",
        "# Get the SHAP values for this single sample\n",
        "# We're interested in class 1 (\"Yes\")\n",
        "shap_values_sample = explainer.shap_values(X_sample)[1]\n",
        "\n",
        "# Get the model's base value (the average prediction)\n",
        "base_value = explainer.expected_value[1]\n",
        "\n",
        "st.write(\"---\")\n",
        "st.write(f\"### Explaining Prediction for a Single User\")\n",
        "\n",
        "# Create a waterfall plot\n",
        "shap.waterfall_plot(shap.Explanation(\n",
        "    values=shap_values_sample[0],\n",
        "    base_values=base_value,\n",
        "    data=X_sample.iloc[0],\n",
        "    feature_names=X_test.columns.tolist()\n",
        "), show=False)\n",
        "st.pyplot(bbox_inches='tight')"
      ],
      "metadata": {
        "id": "N3N8jEsoTG_P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}